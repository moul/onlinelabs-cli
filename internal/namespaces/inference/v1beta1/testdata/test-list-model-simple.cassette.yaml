---
version: 1
interactions:
- request:
    body: '{"models":[{"id":"6c68b256-ef4a-48d2-a794-9b63b5c6ba5d", "name":"meta/llama-3-8b-instruct:bf16",
      "project_id":"", "tags":["instruct", "chat"], "description":"Efficient 8B-param
      model by Meta, fine-tuned for instruction and automation.", "is_public":true,
      "created_at":"2024-03-14T00:00:00Z", "updated_at":"2024-06-25T12:11:33.374529Z",
      "has_eula":true, "provider":"meta", "compatible_node_types":["L4"], "quantization_level":"bf16",
      "region":"fr-par"}, {"id":"a7db3243-9d6a-4149-9ffb-081e24886d00", "name":"mistral/mixtral-8x7b-instruct-v0.1:fp16",
      "project_id":"", "tags":["instruct", "chat"], "description":"A high-quality
      Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under
      Apache 2.0.", "is_public":true, "created_at":"2024-03-15T00:00:00Z", "updated_at":"2024-06-25T12:11:33.317896Z",
      "has_eula":false, "provider":"mistral", "compatible_node_types":["H100-2"],
      "quantization_level":"fp16", "region":"fr-par"}, {"id":"c55d11d3-f717-4ede-82ac-48a74b84cbf1",
      "name":"mistral/mixtral-8x7b-instruct-v0.1:int8", "project_id":"", "tags":["instruct",
      "chat"], "description":"A high-quality Mixture of Experts (MoE) model with open
      weights by Mistral AI, licensed under Apache 2.0.", "is_public":true, "created_at":"2024-03-15T00:00:00Z",
      "updated_at":"2024-06-25T12:11:33.337672Z", "has_eula":false, "provider":"mistral",
      "compatible_node_types":["H100"], "quantization_level":"int8", "region":"fr-par"},
      {"id":"3077ebd3-3a5a-47fc-91c2-da8cf6779c56", "name":"wizardlm/wizardlm-70b-v1.0:fp16",
      "project_id":"", "tags":["instruct", "chat"], "description":"General use 70B-param
      model based on Llama 2.", "is_public":true, "created_at":"2024-03-15T12:00:00Z",
      "updated_at":"2024-06-25T12:11:33.359473Z", "has_eula":true, "provider":"wizardlm",
      "compatible_node_types":["H100-2"], "quantization_level":"fp16", "region":"fr-par"},
      {"id":"729c0386-ddde-4209-ba91-fad5ec47e2bb", "name":"wizardlm/wizardlm-70b-v1.0:fp8",
      "project_id":"", "tags":["instruct"], "description":"Empowering Large Pre-Trained
      Language Models to Follow Complex Instructions", "is_public":true, "created_at":"2024-03-15T12:00:00Z",
      "updated_at":null, "has_eula":true, "provider":"wizardlm", "compatible_node_types":["H100"],
      "quantization_level":"fp8", "region":"fr-par"}, {"id":"4d834112-ed88-4394-9035-6eea562ec5f5",
      "name":"sentence-transformers/sentence-t5-xxl:fp32", "project_id":"", "tags":["embedding"],
      "description":"Model from pre-trained Text-to-Text sentence encode.", "is_public":true,
      "created_at":"2024-05-28T08:45:33.705028Z", "updated_at":"2024-06-25T12:11:33.403176Z",
      "has_eula":false, "provider":"sentence-transformers", "compatible_node_types":["L4"],
      "quantization_level":"fp32", "region":"fr-par"}, {"id":"12c8b72a-720e-4482-b9e1-527f7d8b7aea",
      "name":"meta/llama-3-70b-instruct:int8", "project_id":"", "tags":["instruct",
      "chat"], "description":"Latest 70B-param model from Meta, fine-tuned for instruction
      and automation.", "is_public":true, "created_at":"2024-05-28T13:51:48.533257Z",
      "updated_at":"2024-06-25T12:11:33.390246Z", "has_eula":true, "provider":"meta",
      "compatible_node_types":["H100"], "quantization_level":"int8", "region":"fr-par"}],
      "total_count":7}'
    form: {}
    headers:
      User-Agent:
      - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.22.2; darwin; amd64) cli-e2e-test
    url: https://api.scaleway.com/inference/v1beta1/regions/fr-par/models?order_by=created_at_asc&page=1
    method: GET
  response:
    body: '{"models":[{"id":"6c68b256-ef4a-48d2-a794-9b63b5c6ba5d", "name":"meta/llama-3-8b-instruct:bf16",
      "project_id":"", "tags":["instruct", "chat"], "description":"Efficient 8B-param
      model by Meta, fine-tuned for instruction and automation.", "is_public":true,
      "created_at":"2024-03-14T00:00:00Z", "updated_at":"2024-06-25T12:11:33.374529Z",
      "has_eula":true, "provider":"meta", "compatible_node_types":["L4"], "quantization_level":"bf16",
      "region":"fr-par"}, {"id":"a7db3243-9d6a-4149-9ffb-081e24886d00", "name":"mistral/mixtral-8x7b-instruct-v0.1:fp16",
      "project_id":"", "tags":["instruct", "chat"], "description":"A high-quality
      Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under
      Apache 2.0.", "is_public":true, "created_at":"2024-03-15T00:00:00Z", "updated_at":"2024-06-25T12:11:33.317896Z",
      "has_eula":false, "provider":"mistral", "compatible_node_types":["H100-2"],
      "quantization_level":"fp16", "region":"fr-par"}, {"id":"c55d11d3-f717-4ede-82ac-48a74b84cbf1",
      "name":"mistral/mixtral-8x7b-instruct-v0.1:int8", "project_id":"", "tags":["instruct",
      "chat"], "description":"A high-quality Mixture of Experts (MoE) model with open
      weights by Mistral AI, licensed under Apache 2.0.", "is_public":true, "created_at":"2024-03-15T00:00:00Z",
      "updated_at":"2024-06-25T12:11:33.337672Z", "has_eula":false, "provider":"mistral",
      "compatible_node_types":["H100"], "quantization_level":"int8", "region":"fr-par"},
      {"id":"3077ebd3-3a5a-47fc-91c2-da8cf6779c56", "name":"wizardlm/wizardlm-70b-v1.0:fp16",
      "project_id":"", "tags":["instruct", "chat"], "description":"General use 70B-param
      model based on Llama 2.", "is_public":true, "created_at":"2024-03-15T12:00:00Z",
      "updated_at":"2024-06-25T12:11:33.359473Z", "has_eula":true, "provider":"wizardlm",
      "compatible_node_types":["H100-2"], "quantization_level":"fp16", "region":"fr-par"},
      {"id":"729c0386-ddde-4209-ba91-fad5ec47e2bb", "name":"wizardlm/wizardlm-70b-v1.0:fp8",
      "project_id":"", "tags":["instruct"], "description":"Empowering Large Pre-Trained
      Language Models to Follow Complex Instructions", "is_public":true, "created_at":"2024-03-15T12:00:00Z",
      "updated_at":null, "has_eula":true, "provider":"wizardlm", "compatible_node_types":["H100"],
      "quantization_level":"fp8", "region":"fr-par"}, {"id":"4d834112-ed88-4394-9035-6eea562ec5f5",
      "name":"sentence-transformers/sentence-t5-xxl:fp32", "project_id":"", "tags":["embedding"],
      "description":"Model from pre-trained Text-to-Text sentence encode.", "is_public":true,
      "created_at":"2024-05-28T08:45:33.705028Z", "updated_at":"2024-06-25T12:11:33.403176Z",
      "has_eula":false, "provider":"sentence-transformers", "compatible_node_types":["L4"],
      "quantization_level":"fp32", "region":"fr-par"}, {"id":"12c8b72a-720e-4482-b9e1-527f7d8b7aea",
      "name":"meta/llama-3-70b-instruct:int8", "project_id":"", "tags":["instruct",
      "chat"], "description":"Latest 70B-param model from Meta, fine-tuned for instruction
      and automation.", "is_public":true, "created_at":"2024-05-28T13:51:48.533257Z",
      "updated_at":"2024-06-25T12:11:33.390246Z", "has_eula":true, "provider":"meta",
      "compatible_node_types":["H100"], "quantization_level":"int8", "region":"fr-par"}],
      "total_count":7}'
    headers:
      Content-Length:
      - "3182"
      Content-Security-Policy:
      - default-src 'none'; frame-ancestors 'none'
      Content-Type:
      - application/json
      Date:
      - Wed, 26 Jun 2024 17:10:05 GMT
      Server:
      - Scaleway API Gateway (fr-par-1;edge03)
      Strict-Transport-Security:
      - max-age=63072000
      X-Content-Type-Options:
      - nosniff
      X-Frame-Options:
      - DENY
      X-Request-Id:
      - bdeb5026-6051-4f7e-8f0a-94449f8647b1
    status: 200 OK
    code: 200
    duration: ""
