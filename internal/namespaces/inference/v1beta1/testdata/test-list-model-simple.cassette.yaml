---
version: 1
interactions:
- request:
    body: '{"models":[{"id":"6c68b256-ef4a-48d2-a794-9b63b5c6ba5d", "name":"meta/llama-3-8b-instruct:bf16",
      "project_id":"", "tags":["instruct", "chat"], "description":"Efficient 8B-param
      model by Meta, fine-tuned for instruction and automation.", "is_public":true,
      "created_at":"2024-03-14T00:00:00Z", "updated_at":"2024-07-10T07:49:19.674638Z",
      "has_eula":true, "provider":"meta", "compatible_node_types":["L4"], "quantization_level":"bf16",
      "region":"fr-par"}, {"id":"12c8b72a-720e-4482-b9e1-527f7d8b7aea", "name":"meta/llama-3-70b-instruct:int8",
      "project_id":"", "tags":["instruct", "chat"], "description":"Latest 70B-param
      model from Meta, fine-tuned for instruction and automation.", "is_public":true,
      "created_at":"2024-05-28T13:51:48.533257Z", "updated_at":"2024-07-10T07:49:19.690626Z",
      "has_eula":true, "provider":"meta", "compatible_node_types":["H100"], "quantization_level":"int8",
      "region":"fr-par"}, {"id":"8519601b-1e51-44b4-a603-5622a31ce75a", "name":"mistral/mistral-7b-instruct-v0.3:bf16",
      "project_id":"", "tags":["instruct", "chat"], "description":"A very efficient
      language model by Mistral AI, optimized for instruction-following tasks. Available
      under the Apache 2.0 license.", "is_public":true, "created_at":"2024-06-27T13:18:47.072485Z",
      "updated_at":"2024-07-10T07:49:19.721287Z", "has_eula":false, "provider":"mistral",
      "compatible_node_types":["L4"], "quantization_level":"bf16", "region":"fr-par"},
      {"id":"c55d11d3-f717-4ede-82ac-48a74b84cbf1", "name":"mistral/mixtral-8x7b-instruct-v0.1:int8",
      "project_id":"", "tags":["instruct", "chat"], "description":"A high-quality
      Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under
      Apache 2.0.", "is_public":true, "created_at":"2024-03-15T00:00:00Z", "updated_at":"2024-07-10T07:49:19.636634Z",
      "has_eula":false, "provider":"mistral", "compatible_node_types":["H100"], "quantization_level":"int8",
      "region":"fr-par"}, {"id":"a7db3243-9d6a-4149-9ffb-081e24886d00", "name":"mistral/mixtral-8x7b-instruct-v0.1:fp16",
      "project_id":"", "tags":["instruct", "chat"], "description":"A high-quality
      Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under
      Apache 2.0.", "is_public":true, "created_at":"2024-03-15T00:00:00Z", "updated_at":"2024-07-10T07:49:19.615191Z",
      "has_eula":false, "provider":"mistral", "compatible_node_types":["H100-2"],
      "quantization_level":"fp16", "region":"fr-par"}, {"id":"3077ebd3-3a5a-47fc-91c2-da8cf6779c56",
      "name":"wizardlm/wizardlm-70b-v1.0:fp16", "project_id":"", "tags":["instruct",
      "chat"], "description":"General use 70B-param model based on Llama 2.", "is_public":true,
      "created_at":"2024-03-15T12:00:00Z", "updated_at":"2024-07-10T07:49:19.656984Z",
      "has_eula":true, "provider":"wizardlm", "compatible_node_types":["H100-2"],
      "quantization_level":"fp16", "region":"fr-par"}, {"id":"4d834112-ed88-4394-9035-6eea562ec5f5",
      "name":"sentence-transformers/sentence-t5-xxl:fp32", "project_id":"", "tags":["embedding"],
      "description":"Model from pre-trained Text-to-Text sentence encode.", "is_public":true,
      "created_at":"2024-05-28T08:45:33.705028Z", "updated_at":"2024-07-10T07:49:19.705070Z",
      "has_eula":false, "provider":"sentence-transformers", "compatible_node_types":["L4"],
      "quantization_level":"fp32", "region":"fr-par"}, {"id":"729c0386-ddde-4209-ba91-fad5ec47e2bb",
      "name":"wizardlm/wizardlm-70b-v1.0:fp8", "project_id":"", "tags":["instruct"],
      "description":"Empowering Large Pre-Trained Language Models to Follow Complex
      Instructions", "is_public":true, "created_at":"2024-03-15T12:00:00Z", "updated_at":null,
      "has_eula":true, "provider":"wizardlm", "compatible_node_types":["H100"], "quantization_level":"fp8",
      "region":"fr-par"}], "total_count":8}'
    form: {}
    headers:
      User-Agent:
      - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.22.2; darwin; amd64) cli-e2e-test
    url: https://api.scaleway.com/inference/v1beta1/regions/fr-par/models?order_by=display_rank_asc&page=1
    method: GET
  response:
    body: '{"models":[{"id":"6c68b256-ef4a-48d2-a794-9b63b5c6ba5d", "name":"meta/llama-3-8b-instruct:bf16",
      "project_id":"", "tags":["instruct", "chat"], "description":"Efficient 8B-param
      model by Meta, fine-tuned for instruction and automation.", "is_public":true,
      "created_at":"2024-03-14T00:00:00Z", "updated_at":"2024-07-10T07:49:19.674638Z",
      "has_eula":true, "provider":"meta", "compatible_node_types":["L4"], "quantization_level":"bf16",
      "region":"fr-par"}, {"id":"12c8b72a-720e-4482-b9e1-527f7d8b7aea", "name":"meta/llama-3-70b-instruct:int8",
      "project_id":"", "tags":["instruct", "chat"], "description":"Latest 70B-param
      model from Meta, fine-tuned for instruction and automation.", "is_public":true,
      "created_at":"2024-05-28T13:51:48.533257Z", "updated_at":"2024-07-10T07:49:19.690626Z",
      "has_eula":true, "provider":"meta", "compatible_node_types":["H100"], "quantization_level":"int8",
      "region":"fr-par"}, {"id":"8519601b-1e51-44b4-a603-5622a31ce75a", "name":"mistral/mistral-7b-instruct-v0.3:bf16",
      "project_id":"", "tags":["instruct", "chat"], "description":"A very efficient
      language model by Mistral AI, optimized for instruction-following tasks. Available
      under the Apache 2.0 license.", "is_public":true, "created_at":"2024-06-27T13:18:47.072485Z",
      "updated_at":"2024-07-10T07:49:19.721287Z", "has_eula":false, "provider":"mistral",
      "compatible_node_types":["L4"], "quantization_level":"bf16", "region":"fr-par"},
      {"id":"c55d11d3-f717-4ede-82ac-48a74b84cbf1", "name":"mistral/mixtral-8x7b-instruct-v0.1:int8",
      "project_id":"", "tags":["instruct", "chat"], "description":"A high-quality
      Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under
      Apache 2.0.", "is_public":true, "created_at":"2024-03-15T00:00:00Z", "updated_at":"2024-07-10T07:49:19.636634Z",
      "has_eula":false, "provider":"mistral", "compatible_node_types":["H100"], "quantization_level":"int8",
      "region":"fr-par"}, {"id":"a7db3243-9d6a-4149-9ffb-081e24886d00", "name":"mistral/mixtral-8x7b-instruct-v0.1:fp16",
      "project_id":"", "tags":["instruct", "chat"], "description":"A high-quality
      Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under
      Apache 2.0.", "is_public":true, "created_at":"2024-03-15T00:00:00Z", "updated_at":"2024-07-10T07:49:19.615191Z",
      "has_eula":false, "provider":"mistral", "compatible_node_types":["H100-2"],
      "quantization_level":"fp16", "region":"fr-par"}, {"id":"3077ebd3-3a5a-47fc-91c2-da8cf6779c56",
      "name":"wizardlm/wizardlm-70b-v1.0:fp16", "project_id":"", "tags":["instruct",
      "chat"], "description":"General use 70B-param model based on Llama 2.", "is_public":true,
      "created_at":"2024-03-15T12:00:00Z", "updated_at":"2024-07-10T07:49:19.656984Z",
      "has_eula":true, "provider":"wizardlm", "compatible_node_types":["H100-2"],
      "quantization_level":"fp16", "region":"fr-par"}, {"id":"4d834112-ed88-4394-9035-6eea562ec5f5",
      "name":"sentence-transformers/sentence-t5-xxl:fp32", "project_id":"", "tags":["embedding"],
      "description":"Model from pre-trained Text-to-Text sentence encode.", "is_public":true,
      "created_at":"2024-05-28T08:45:33.705028Z", "updated_at":"2024-07-10T07:49:19.705070Z",
      "has_eula":false, "provider":"sentence-transformers", "compatible_node_types":["L4"],
      "quantization_level":"fp32", "region":"fr-par"}, {"id":"729c0386-ddde-4209-ba91-fad5ec47e2bb",
      "name":"wizardlm/wizardlm-70b-v1.0:fp8", "project_id":"", "tags":["instruct"],
      "description":"Empowering Large Pre-Trained Language Models to Follow Complex
      Instructions", "is_public":true, "created_at":"2024-03-15T12:00:00Z", "updated_at":null,
      "has_eula":true, "provider":"wizardlm", "compatible_node_types":["H100"], "quantization_level":"fp8",
      "region":"fr-par"}], "total_count":8}'
    headers:
      Content-Length:
      - "3696"
      Content-Security-Policy:
      - default-src 'none'; frame-ancestors 'none'
      Content-Type:
      - application/json
      Date:
      - Wed, 10 Jul 2024 14:34:34 GMT
      Server:
      - Scaleway API Gateway (fr-par-3;edge01)
      Strict-Transport-Security:
      - max-age=63072000
      X-Content-Type-Options:
      - nosniff
      X-Frame-Options:
      - DENY
      X-Request-Id:
      - 305725ff-1f57-413b-9c71-5eed5706696a
    status: 200 OK
    code: 200
    duration: ""
